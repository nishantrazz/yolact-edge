{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '_psutil_linux' could not be imported from 'most likely due to a circular import'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"canopy11s640.pt\")\n",
    "\n",
    "# model.export(format=\"engine\", device=\"cuda:0\")  # Ensure model runs on GPU\n",
    "\n",
    "# model.export(\n",
    "#     format=\"engine\",\n",
    "#     dynamic=True,  \n",
    "#     batch=4,  \n",
    "#     workspace=4,  \n",
    "#     int8=True\n",
    "# )\n",
    "\n",
    "\n",
    "# TensorRT FP32\n",
    "# model.export(format=\"engine\", imgsz=640, dynamic=True, verbose=False, batch=8, workspace=2)\n",
    "\n",
    "# TensorRT FP16\n",
    "model.export(format=\"engine\", imgsz=640, dynamic=True, batch=2, half=True, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading canopy11s.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 34933.2ms\n",
      "Speed: 10.6ms preprocess, 34933.2ms inference, 23.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 120.3ms\n",
      "Speed: 6.6ms preprocess, 120.3ms inference, 21.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 162.2ms\n",
      "Speed: 7.0ms preprocess, 162.2ms inference, 14.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.9ms\n",
      "Speed: 9.0ms preprocess, 116.9ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 122.4ms\n",
      "Speed: 5.5ms preprocess, 122.4ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 117.0ms\n",
      "Speed: 5.9ms preprocess, 117.0ms inference, 9.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 120.6ms\n",
      "Speed: 8.4ms preprocess, 120.6ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 123.4ms\n",
      "Speed: 5.9ms preprocess, 123.4ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.5ms\n",
      "Speed: 5.5ms preprocess, 116.5ms inference, 12.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 117.2ms\n",
      "Speed: 5.3ms preprocess, 117.2ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 118.4ms\n",
      "Speed: 5.5ms preprocess, 118.4ms inference, 12.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 119.2ms\n",
      "Speed: 6.1ms preprocess, 119.2ms inference, 9.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 117.3ms\n",
      "Speed: 6.1ms preprocess, 117.3ms inference, 11.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 123.1ms\n",
      "Speed: 9.7ms preprocess, 123.1ms inference, 16.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 122.6ms\n",
      "Speed: 5.3ms preprocess, 122.6ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 132.2ms\n",
      "Speed: 9.7ms preprocess, 132.2ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 132.5ms\n",
      "Speed: 6.5ms preprocess, 132.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 128.4ms\n",
      "Speed: 10.4ms preprocess, 128.4ms inference, 11.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 105.8ms\n",
      "Speed: 6.0ms preprocess, 105.8ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 129.8ms\n",
      "Speed: 7.4ms preprocess, 129.8ms inference, 15.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 131.9ms\n",
      "Speed: 11.7ms preprocess, 131.9ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 123.5ms\n",
      "Speed: 6.5ms preprocess, 123.5ms inference, 11.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 134.2ms\n",
      "Speed: 10.1ms preprocess, 134.2ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 126.4ms\n",
      "Speed: 6.1ms preprocess, 126.4ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 130.9ms\n",
      "Speed: 11.5ms preprocess, 130.9ms inference, 13.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 122.9ms\n",
      "Speed: 7.4ms preprocess, 122.9ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 124.9ms\n",
      "Speed: 7.3ms preprocess, 124.9ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.4ms\n",
      "Speed: 7.7ms preprocess, 116.4ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 119.5ms\n",
      "Speed: 5.2ms preprocess, 119.5ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 118.2ms\n",
      "Speed: 7.9ms preprocess, 118.2ms inference, 8.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 109.7ms\n",
      "Speed: 6.1ms preprocess, 109.7ms inference, 11.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 105.1ms\n",
      "Speed: 7.7ms preprocess, 105.1ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 95.2ms\n",
      "Speed: 8.6ms preprocess, 95.2ms inference, 20.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 133.4ms\n",
      "Speed: 5.4ms preprocess, 133.4ms inference, 15.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 136.2ms\n",
      "Speed: 5.9ms preprocess, 136.2ms inference, 13.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 113.5ms\n",
      "Speed: 9.4ms preprocess, 113.5ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 103.5ms\n",
      "Speed: 6.1ms preprocess, 103.5ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 134.4ms\n",
      "Speed: 6.0ms preprocess, 134.4ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 143.9ms\n",
      "Speed: 5.4ms preprocess, 143.9ms inference, 11.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 134.5ms\n",
      "Speed: 6.6ms preprocess, 134.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 125.0ms\n",
      "Speed: 7.9ms preprocess, 125.0ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.9ms\n",
      "Speed: 7.7ms preprocess, 116.9ms inference, 11.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 117.2ms\n",
      "Speed: 7.8ms preprocess, 117.2ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.8ms\n",
      "Speed: 8.7ms preprocess, 116.8ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.1ms\n",
      "Speed: 5.3ms preprocess, 116.1ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 112.4ms\n",
      "Speed: 7.1ms preprocess, 112.4ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 114.7ms\n",
      "Speed: 5.8ms preprocess, 114.7ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 115.7ms\n",
      "Speed: 7.6ms preprocess, 115.7ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 115.1ms\n",
      "Speed: 6.1ms preprocess, 115.1ms inference, 9.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 108.9ms\n",
      "Speed: 8.2ms preprocess, 108.9ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 113.3ms\n",
      "Speed: 7.6ms preprocess, 113.3ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 115.4ms\n",
      "Speed: 5.8ms preprocess, 115.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 114.2ms\n",
      "Speed: 8.7ms preprocess, 114.2ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.2ms\n",
      "Speed: 7.6ms preprocess, 116.2ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 111.1ms\n",
      "Speed: 5.4ms preprocess, 111.1ms inference, 12.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 110.8ms\n",
      "Speed: 9.4ms preprocess, 110.8ms inference, 12.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 114.6ms\n",
      "Speed: 7.4ms preprocess, 114.6ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 112.1ms\n",
      "Speed: 6.0ms preprocess, 112.1ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 112.0ms\n",
      "Speed: 5.9ms preprocess, 112.0ms inference, 12.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 119.4ms\n",
      "Speed: 5.3ms preprocess, 119.4ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 114.2ms\n",
      "Speed: 5.7ms preprocess, 114.2ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 115.6ms\n",
      "Speed: 5.6ms preprocess, 115.6ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 119.8ms\n",
      "Speed: 5.2ms preprocess, 119.8ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 111.1ms\n",
      "Speed: 5.3ms preprocess, 111.1ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.5ms\n",
      "Speed: 5.5ms preprocess, 116.5ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 111.5ms\n",
      "Speed: 5.5ms preprocess, 111.5ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.3ms\n",
      "Speed: 6.3ms preprocess, 116.3ms inference, 13.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.6ms\n",
      "Speed: 6.1ms preprocess, 116.6ms inference, 15.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 117.6ms\n",
      "Speed: 5.3ms preprocess, 117.6ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 116.4ms\n",
      "Speed: 7.6ms preprocess, 116.4ms inference, 9.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 117.0ms\n",
      "Speed: 5.2ms preprocess, 117.0ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 canopys, 2 roads, 114.2ms\n",
      "Speed: 6.6ms preprocess, 114.2ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 112.5ms\n",
      "Speed: 5.4ms preprocess, 112.5ms inference, 9.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 112.0ms\n",
      "Speed: 5.4ms preprocess, 112.0ms inference, 11.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 115.4ms\n",
      "Speed: 10.1ms preprocess, 115.4ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 107.9ms\n",
      "Speed: 5.8ms preprocess, 107.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 133.7ms\n",
      "Speed: 5.7ms preprocess, 133.7ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 129.5ms\n",
      "Speed: 6.9ms preprocess, 129.5ms inference, 14.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 132.3ms\n",
      "Speed: 6.0ms preprocess, 132.3ms inference, 11.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 121.9ms\n",
      "Speed: 7.2ms preprocess, 121.9ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 133.1ms\n",
      "Speed: 7.2ms preprocess, 133.1ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 129.9ms\n",
      "Speed: 8.0ms preprocess, 129.9ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 135.6ms\n",
      "Speed: 5.6ms preprocess, 135.6ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 132.8ms\n",
      "Speed: 6.7ms preprocess, 132.8ms inference, 13.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 133.6ms\n",
      "Speed: 6.3ms preprocess, 133.6ms inference, 15.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 133.6ms\n",
      "Speed: 6.0ms preprocess, 133.6ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 106.6ms\n",
      "Speed: 9.8ms preprocess, 106.6ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 99.0ms\n",
      "Speed: 6.7ms preprocess, 99.0ms inference, 17.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 130.7ms\n",
      "Speed: 5.4ms preprocess, 130.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 113.8ms\n",
      "Speed: 8.5ms preprocess, 113.8ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 113.8ms\n",
      "Speed: 7.6ms preprocess, 113.8ms inference, 11.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 112.5ms\n",
      "Speed: 7.0ms preprocess, 112.5ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 116.6ms\n",
      "Speed: 5.3ms preprocess, 116.6ms inference, 12.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 127.2ms\n",
      "Speed: 8.2ms preprocess, 127.2ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 124.0ms\n",
      "Speed: 10.2ms preprocess, 124.0ms inference, 14.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 129.4ms\n",
      "Speed: 5.9ms preprocess, 129.4ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 113.2ms\n",
      "Speed: 5.3ms preprocess, 113.2ms inference, 9.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 113.7ms\n",
      "Speed: 5.5ms preprocess, 113.7ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 canopys, 2 roads, 117.0ms\n",
      "Speed: 5.2ms preprocess, 117.0ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Load the exported TensorRT model with instance segmentation\n",
    "model = YOLO(\"canopy.engine\", task=\"segment\")  # Enable segmentation\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"DJI_0008.MOV\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = 320 # int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = 240 # int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize time and frame count for FPS calculation\n",
    "prev_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Break the loop if video ends\n",
    "\n",
    "    # Resize the frame to 640x640\n",
    "    frame_resized = cv2.resize(frame, (320, 240))\n",
    "\n",
    "    # Run inference on the resized frame\n",
    "    results = model(frame_resized)\n",
    "\n",
    "    # Draw the detections on the frame\n",
    "    for result in results:\n",
    "        annotated_frame = result.plot()\n",
    "\n",
    "    # Calculate FPS\n",
    "    frame_count += 1\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - prev_time\n",
    "    if elapsed_time > 0:\n",
    "        fps = frame_count / elapsed_time\n",
    "    else:\n",
    "        fps = 0\n",
    "\n",
    "    # Display FPS on the frame\n",
    "    cv2.putText(annotated_frame, f\"FPS: {fps:.2f}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"YOLO Instance Segmentation\", annotated_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Press 'q' to exit early\n",
    "        break\n",
    "\n",
    "# Release everything\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (8 CPUs, 15.0 GB RAM, 34.9/233.7 GB disk)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'key' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanopy11s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Benchmark YOLO11n speed and accuracy on the COCO8 dataset for all all export formats\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco8.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/engine/model.py:683\u001b[0m, in \u001b[0;36mModel.benchmark\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[1;32m    682\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if no 'data' argument passed set data=None for default datasets\u001b[39;49;00m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimgsz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhalf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint8\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/utils/benchmarks.py:183\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(model, data, imgsz, half, int8, device, verbose, eps, format)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    182\u001b[0m check_yolo(device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# print system info\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus❔\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize (MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mkey\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference time (ms/im)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPS\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    185\u001b[0m name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[1;32m    186\u001b[0m dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'key' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a YOLO11n PyTorch model\n",
    "model = YOLO(\"canopy11s.pt\")\n",
    "\n",
    "# Benchmark YOLO11n speed and accuracy on the COCO8 dataset for all all export formats\n",
    "results = model.benchmark(data=\"coco8.yaml\", imgsz=640, format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
